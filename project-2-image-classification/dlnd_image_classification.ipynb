{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe97418a860>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #return (x-0)/(255-0)\n",
    "    normalized_image = np.array (x / x.max())\n",
    "    return normalized_image\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #print(x[2])\n",
    "    one_hot = np.zeros((len(x), 10))\n",
    "    for i in range(len(x)):\n",
    "        one_hot[i,x[i]] = 1\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #print(image_shape[0])\n",
    "    return tf.placeholder(tf.float32, [None, image_shape[0], image_shape[1], image_shape[2]], \"x\" )\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], \"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, None, \"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Weights = tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], x_tensor.get_shape().as_list()[3], conv_num_outputs],mean=0.0,stddev = 0.1))\n",
    "    bias = tf.Variable(tf.zeros([conv_num_outputs]))            \n",
    "    y = tf.nn.conv2d(x_tensor, Weights, strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
    "    y = tf.nn.bias_add(y, bias)        \n",
    "    y = tf.nn.relu(y)\n",
    "    y = tf.nn.max_pool(y, ksize=[1, pool_ksize[0], pool_ksize[1], 1], strides=[1, pool_strides[0], pool_strides[1], 1], padding='SAME')      \n",
    "    return y\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #s = x_tensor.get_shape()\n",
    "    #flatten_image_size = np.prod([i for i in s[1:]])\n",
    "    #print(flatten_image_size)\n",
    "    #new_s = [-1, flatten_image_size.value]\n",
    "    #return tf.reshape(x_tensor, new_s)\n",
    "    flatImageSize = x_tensor.get_shape().as_list()[1]*x_tensor.get_shape().as_list()[2]*x_tensor.get_shape().as_list()[3]\n",
    "    res = tf.reshape(x_tensor, [-1,flatImageSize])\n",
    "    return res\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #return tfl.layers.dense(inputs=x_tensor, units=num_outputs, activation=tf.nn.relu)\n",
    "    return tf.contrib.layers.fully_connected(inputs=x_tensor, num_outputs = num_outputs, activation_fn=tf.nn.relu)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.fully_connected(inputs=x_tensor, num_outputs = num_outputs, activation_fn=None)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    model = conv2d_maxpool(x, conv_num_outputs=18, conv_ksize=(4,4), conv_strides=(1,1), pool_ksize=(8,8), pool_strides=(1,1))\n",
    "   \n",
    "    \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    model = flatten(model)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    model = fully_conn(model,300)\n",
    "    model = tf.nn.dropout(model, keep_prob)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    model = output(model,10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return model\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x:feature_batch, y:label_batch, keep_prob:keep_probability})\n",
    "    return\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.0})\n",
    "    validation_accuracy = sess.run(accuracy, feed_dict={\n",
    "                x: valid_features,\n",
    "                y: valid_labels,\n",
    "                keep_prob: 1.0})\n",
    "    print(\"Loss: {} Validation Accuracy: {}\".format(loss, validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 90\n",
    "batch_size = 512\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.293170928955078 Validation Accuracy: 0.12239998579025269\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 2.2567553520202637 Validation Accuracy: 0.15160000324249268\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 2.175419330596924 Validation Accuracy: 0.23099999129772186\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 2.084639549255371 Validation Accuracy: 0.2443999946117401\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 2.0190494060516357 Validation Accuracy: 0.30159997940063477\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 1.9538553953170776 Validation Accuracy: 0.3715999722480774\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 1.8602544069290161 Validation Accuracy: 0.36419999599456787\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 1.7742785215377808 Validation Accuracy: 0.4049999713897705\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 1.7361185550689697 Validation Accuracy: 0.4187999665737152\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 1.6703377962112427 Validation Accuracy: 0.4487999677658081\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 1.6067755222320557 Validation Accuracy: 0.4535999298095703\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 1.5639363527297974 Validation Accuracy: 0.46439996361732483\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 1.5125551223754883 Validation Accuracy: 0.4875999689102173\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 1.520516276359558 Validation Accuracy: 0.488599956035614\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 1.437770962715149 Validation Accuracy: 0.5057999491691589\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 1.4193925857543945 Validation Accuracy: 0.5025999546051025\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 1.3965964317321777 Validation Accuracy: 0.5041999220848083\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 1.3735225200653076 Validation Accuracy: 0.4979999363422394\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 1.3677171468734741 Validation Accuracy: 0.5067999958992004\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 1.3762964010238647 Validation Accuracy: 0.5131999254226685\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 1.3137378692626953 Validation Accuracy: 0.5117999315261841\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 1.2824957370758057 Validation Accuracy: 0.5275999307632446\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 1.2636293172836304 Validation Accuracy: 0.5221999287605286\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 1.2376385927200317 Validation Accuracy: 0.5161999464035034\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 1.2479722499847412 Validation Accuracy: 0.5305999517440796\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 1.235137701034546 Validation Accuracy: 0.5251999497413635\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 1.201053261756897 Validation Accuracy: 0.5323999524116516\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 1.21046781539917 Validation Accuracy: 0.5277999639511108\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 1.1693625450134277 Validation Accuracy: 0.5371999740600586\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 1.1527025699615479 Validation Accuracy: 0.5381999015808105\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 1.1196343898773193 Validation Accuracy: 0.5463999509811401\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 1.1584265232086182 Validation Accuracy: 0.531999945640564\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 1.1496058702468872 Validation Accuracy: 0.5339999794960022\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 1.1134898662567139 Validation Accuracy: 0.5483999252319336\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 1.1096620559692383 Validation Accuracy: 0.5383999347686768\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 1.1103003025054932 Validation Accuracy: 0.539199948310852\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 1.0902436971664429 Validation Accuracy: 0.5411999821662903\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 1.1072745323181152 Validation Accuracy: 0.5363999605178833\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 1.0612455606460571 Validation Accuracy: 0.5427999496459961\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 1.0639041662216187 Validation Accuracy: 0.5501999258995056\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 1.0687406063079834 Validation Accuracy: 0.5351999402046204\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 1.0217833518981934 Validation Accuracy: 0.546799898147583\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 1.0467970371246338 Validation Accuracy: 0.5437999367713928\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 1.0025880336761475 Validation Accuracy: 0.5501999258995056\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 1.0600476264953613 Validation Accuracy: 0.5375999212265015\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 1.0169905424118042 Validation Accuracy: 0.5481999516487122\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 1.0063111782073975 Validation Accuracy: 0.5445999503135681\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 0.9869881868362427 Validation Accuracy: 0.5471999645233154\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 0.9860990047454834 Validation Accuracy: 0.5487999320030212\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 0.9764625430107117 Validation Accuracy: 0.5565999746322632\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 0.9869204759597778 Validation Accuracy: 0.5463999509811401\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 0.9858690500259399 Validation Accuracy: 0.5437999367713928\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 0.9690299034118652 Validation Accuracy: 0.5453999638557434\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 0.9303749203681946 Validation Accuracy: 0.5563998818397522\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 0.9708185791969299 Validation Accuracy: 0.544999897480011\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 0.9510782361030579 Validation Accuracy: 0.5509999394416809\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 0.9229981899261475 Validation Accuracy: 0.548799991607666\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 0.9375441074371338 Validation Accuracy: 0.5531998872756958\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 0.9271161556243896 Validation Accuracy: 0.553399920463562\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 0.917239785194397 Validation Accuracy: 0.5447999238967896\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss: 0.9098086953163147 Validation Accuracy: 0.5461999177932739\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss: 0.8908639550209045 Validation Accuracy: 0.5535999536514282\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss: 0.9001078009605408 Validation Accuracy: 0.5511999130249023\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss: 0.8853687047958374 Validation Accuracy: 0.5491999387741089\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss: 0.88616943359375 Validation Accuracy: 0.5550000071525574\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss: 0.8922876119613647 Validation Accuracy: 0.5523999333381653\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss: 0.9180357456207275 Validation Accuracy: 0.5421999096870422\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss: 0.9146308898925781 Validation Accuracy: 0.5415999293327332\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss: 0.8709824085235596 Validation Accuracy: 0.5491999387741089\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss: 0.8992856740951538 Validation Accuracy: 0.5513999462127686\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss: 0.8979777693748474 Validation Accuracy: 0.5467999577522278\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss: 0.8754945397377014 Validation Accuracy: 0.5451998710632324\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss: 0.9055721759796143 Validation Accuracy: 0.5365999937057495\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss: 0.9039291739463806 Validation Accuracy: 0.5457999110221863\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss: 0.8598058223724365 Validation Accuracy: 0.5443999171257019\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss: 0.8990828394889832 Validation Accuracy: 0.5485999584197998\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss: 0.8002548217773438 Validation Accuracy: 0.564799964427948\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss: 0.858954906463623 Validation Accuracy: 0.5549999475479126\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss: 0.813840389251709 Validation Accuracy: 0.5639998912811279\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss: 0.8209012746810913 Validation Accuracy: 0.5639999508857727\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss: 0.7967056035995483 Validation Accuracy: 0.5629999041557312\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss: 0.8316732048988342 Validation Accuracy: 0.5621998906135559\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss: 0.8148729801177979 Validation Accuracy: 0.56659996509552\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss: 0.8119469881057739 Validation Accuracy: 0.5601999163627625\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss: 0.7989146709442139 Validation Accuracy: 0.5717999339103699\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss: 0.8482969999313354 Validation Accuracy: 0.5575999617576599\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss: 0.8193492889404297 Validation Accuracy: 0.5561999678611755\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss: 0.7982264757156372 Validation Accuracy: 0.5553999543190002\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss: 0.797816812992096 Validation Accuracy: 0.5549999475479126\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss: 0.7890375852584839 Validation Accuracy: 0.5583999156951904\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.178431749343872 Validation Accuracy: 0.2199999839067459\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss: 2.0177502632141113 Validation Accuracy: 0.3027999997138977\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss: 1.7101054191589355 Validation Accuracy: 0.3893999457359314\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss: 1.5655996799468994 Validation Accuracy: 0.42639994621276855\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss: 1.5608330965042114 Validation Accuracy: 0.4544000029563904\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 1.5111572742462158 Validation Accuracy: 0.4853999614715576\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss: 1.3530811071395874 Validation Accuracy: 0.5021999478340149\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss: 1.2995492219924927 Validation Accuracy: 0.50819993019104\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss: 1.2227002382278442 Validation Accuracy: 0.5311999320983887\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss: 1.3178383111953735 Validation Accuracy: 0.5375999808311462\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 1.3161382675170898 Validation Accuracy: 0.5471999645233154\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss: 1.24037504196167 Validation Accuracy: 0.5527998805046082\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss: 1.201561689376831 Validation Accuracy: 0.5559999346733093\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss: 1.1161689758300781 Validation Accuracy: 0.5689999461174011\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss: 1.1871429681777954 Validation Accuracy: 0.5735999345779419\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 1.2437753677368164 Validation Accuracy: 0.5611999034881592\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss: 1.171044111251831 Validation Accuracy: 0.5625998973846436\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss: 1.1069464683532715 Validation Accuracy: 0.5783998966217041\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss: 1.0709893703460693 Validation Accuracy: 0.5743999481201172\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss: 1.1171917915344238 Validation Accuracy: 0.579599916934967\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 1.1715935468673706 Validation Accuracy: 0.5819998979568481\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss: 1.1043850183486938 Validation Accuracy: 0.5701999664306641\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss: 1.0634561777114868 Validation Accuracy: 0.5893999338150024\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss: 1.0040562152862549 Validation Accuracy: 0.5903998613357544\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss: 1.0609288215637207 Validation Accuracy: 0.5969998836517334\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 1.1140596866607666 Validation Accuracy: 0.5979999303817749\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss: 1.0961629152297974 Validation Accuracy: 0.584399938583374\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss: 1.015088438987732 Validation Accuracy: 0.6023999452590942\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss: 0.9928330183029175 Validation Accuracy: 0.5977998971939087\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss: 1.0229520797729492 Validation Accuracy: 0.6043999195098877\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 1.0851067304611206 Validation Accuracy: 0.6063999533653259\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss: 1.0491551160812378 Validation Accuracy: 0.5923999547958374\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss: 0.9677259922027588 Validation Accuracy: 0.6085999011993408\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss: 0.9671079516410828 Validation Accuracy: 0.6091998815536499\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss: 1.0103709697723389 Validation Accuracy: 0.6121999025344849\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 1.0549137592315674 Validation Accuracy: 0.6127999424934387\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss: 1.018349051475525 Validation Accuracy: 0.5957999229431152\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss: 0.9635912775993347 Validation Accuracy: 0.6133999228477478\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss: 0.9422575235366821 Validation Accuracy: 0.6161999106407166\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss: 0.9876810312271118 Validation Accuracy: 0.6123999357223511\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 1.0497543811798096 Validation Accuracy: 0.6037999391555786\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss: 1.0042246580123901 Validation Accuracy: 0.6103999018669128\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss: 0.9276787638664246 Validation Accuracy: 0.6203998923301697\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss: 0.9384828805923462 Validation Accuracy: 0.6239999532699585\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss: 0.9364182353019714 Validation Accuracy: 0.6191998720169067\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 1.022387981414795 Validation Accuracy: 0.6227998733520508\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss: 0.9526766538619995 Validation Accuracy: 0.6231998801231384\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss: 0.902299165725708 Validation Accuracy: 0.63239985704422\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss: 0.8990755081176758 Validation Accuracy: 0.6307998895645142\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss: 0.9224233031272888 Validation Accuracy: 0.6283999681472778\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 0.9941248893737793 Validation Accuracy: 0.626599907875061\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss: 0.9194616079330444 Validation Accuracy: 0.6317999362945557\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss: 0.9393811821937561 Validation Accuracy: 0.6225999593734741\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss: 0.8795994520187378 Validation Accuracy: 0.6365998983383179\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss: 0.8831855058670044 Validation Accuracy: 0.6295998692512512\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 0.9654713869094849 Validation Accuracy: 0.6281998753547668\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss: 0.9042682647705078 Validation Accuracy: 0.6289998888969421\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss: 0.8596639633178711 Validation Accuracy: 0.6339998841285706\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss: 0.8884340524673462 Validation Accuracy: 0.6349998712539673\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss: 0.8730488419532776 Validation Accuracy: 0.6317999362945557\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 0.9427515268325806 Validation Accuracy: 0.6367998719215393\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss: 0.8978641629219055 Validation Accuracy: 0.6317998766899109\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss: 0.8577737212181091 Validation Accuracy: 0.6329998970031738\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss: 0.8555710315704346 Validation Accuracy: 0.6417999267578125\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss: 0.8307601809501648 Validation Accuracy: 0.6381999254226685\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 0.9441662430763245 Validation Accuracy: 0.640799880027771\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss: 0.8822680115699768 Validation Accuracy: 0.6321998834609985\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss: 0.8341735601425171 Validation Accuracy: 0.6383998990058899\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss: 0.8609066009521484 Validation Accuracy: 0.6315999031066895\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss: 0.8387157320976257 Validation Accuracy: 0.6327999234199524\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 0.9214178323745728 Validation Accuracy: 0.6423998475074768\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss: 0.8748217821121216 Validation Accuracy: 0.6405999064445496\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss: 0.8180742263793945 Validation Accuracy: 0.6411998867988586\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss: 0.8273131847381592 Validation Accuracy: 0.6421998739242554\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss: 0.8344031572341919 Validation Accuracy: 0.6381999254226685\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 0.9200968146324158 Validation Accuracy: 0.6373999118804932\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss: 0.8811626434326172 Validation Accuracy: 0.6359999179840088\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss: 0.8096383213996887 Validation Accuracy: 0.6395999193191528\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss: 0.82594233751297 Validation Accuracy: 0.6405999064445496\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss: 0.798121452331543 Validation Accuracy: 0.6413998603820801\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 0.8879892826080322 Validation Accuracy: 0.6431999206542969\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss: 0.829358696937561 Validation Accuracy: 0.6433999538421631\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss: 0.7718105316162109 Validation Accuracy: 0.6515998840332031\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss: 0.8084223866462708 Validation Accuracy: 0.6347998976707458\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss: 0.7839071154594421 Validation Accuracy: 0.6401998996734619\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 0.8812103867530823 Validation Accuracy: 0.6451999545097351\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss: 0.8160037994384766 Validation Accuracy: 0.6433998942375183\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss: 0.7719342112541199 Validation Accuracy: 0.6497999429702759\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss: 0.8106867671012878 Validation Accuracy: 0.6467999219894409\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss: 0.7952790260314941 Validation Accuracy: 0.6377999186515808\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 0.8807035684585571 Validation Accuracy: 0.6457998752593994\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss: 0.8108968138694763 Validation Accuracy: 0.6457999348640442\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss: 0.7625711560249329 Validation Accuracy: 0.6463998556137085\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss: 0.7836450338363647 Validation Accuracy: 0.6413998603820801\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss: 0.756162703037262 Validation Accuracy: 0.6429998874664307\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 0.8708392381668091 Validation Accuracy: 0.6511998176574707\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss: 0.8385227918624878 Validation Accuracy: 0.6417999267578125\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss: 0.7731412053108215 Validation Accuracy: 0.6497999429702759\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss: 0.7594640254974365 Validation Accuracy: 0.6495998501777649\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss: 0.7489541172981262 Validation Accuracy: 0.6439999341964722\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 0.8290749192237854 Validation Accuracy: 0.6483998894691467\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss: 0.759842038154602 Validation Accuracy: 0.6533999443054199\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss: 0.7296534776687622 Validation Accuracy: 0.6529999375343323\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss: 0.7416223287582397 Validation Accuracy: 0.6527999639511108\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss: 0.7547800540924072 Validation Accuracy: 0.6427999138832092\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 0.8226675391197205 Validation Accuracy: 0.6435999274253845\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss: 0.7888282537460327 Validation Accuracy: 0.6497999429702759\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss: 0.7387473583221436 Validation Accuracy: 0.6531999111175537\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss: 0.7407647371292114 Validation Accuracy: 0.650999903678894\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss: 0.7176227569580078 Validation Accuracy: 0.6439998745918274\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 0.8128909468650818 Validation Accuracy: 0.645599901676178\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss: 0.7658951282501221 Validation Accuracy: 0.6485998630523682\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss: 0.719353437423706 Validation Accuracy: 0.6495998501777649\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss: 0.7359418869018555 Validation Accuracy: 0.6439999341964722\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss: 0.727943480014801 Validation Accuracy: 0.6499999165534973\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 0.7956737279891968 Validation Accuracy: 0.6489999294281006\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss: 0.7764020562171936 Validation Accuracy: 0.653999924659729\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss: 0.7113760709762573 Validation Accuracy: 0.6515998840332031\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss: 0.7612752318382263 Validation Accuracy: 0.640799880027771\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss: 0.7211618423461914 Validation Accuracy: 0.6447998881340027\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 0.793669581413269 Validation Accuracy: 0.64739990234375\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss: 0.7679234743118286 Validation Accuracy: 0.6505998969078064\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss: 0.7172893285751343 Validation Accuracy: 0.6583999395370483\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss: 0.7225868105888367 Validation Accuracy: 0.6509998440742493\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss: 0.6964526772499084 Validation Accuracy: 0.6489999294281006\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 0.7775236368179321 Validation Accuracy: 0.6457998752593994\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss: 0.7758643627166748 Validation Accuracy: 0.6439999341964722\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss: 0.707435131072998 Validation Accuracy: 0.6447998285293579\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss: 0.7247502207756042 Validation Accuracy: 0.6435998678207397\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss: 0.6911109685897827 Validation Accuracy: 0.6465998888015747\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 0.7719844579696655 Validation Accuracy: 0.6515999436378479\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss: 0.7407864332199097 Validation Accuracy: 0.6467999219894409\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss: 0.7116729021072388 Validation Accuracy: 0.650199830532074\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss: 0.7028036713600159 Validation Accuracy: 0.6521998643875122\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss: 0.690427839756012 Validation Accuracy: 0.6487998962402344\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 0.7808232307434082 Validation Accuracy: 0.6529998779296875\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss: 0.7315671443939209 Validation Accuracy: 0.6581999063491821\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss: 0.6749413013458252 Validation Accuracy: 0.6543998718261719\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss: 0.7078361511230469 Validation Accuracy: 0.642599880695343\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss: 0.6703039407730103 Validation Accuracy: 0.6517999172210693\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 0.7588720321655273 Validation Accuracy: 0.6475998759269714\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss: 0.7362644672393799 Validation Accuracy: 0.6531999111175537\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss: 0.6772356033325195 Validation Accuracy: 0.6531999111175537\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss: 0.664362370967865 Validation Accuracy: 0.6561998128890991\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss: 0.6531187295913696 Validation Accuracy: 0.6519998908042908\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 0.7463234066963196 Validation Accuracy: 0.6577998995780945\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss: 0.7106729745864868 Validation Accuracy: 0.6553999185562134\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss: 0.672042191028595 Validation Accuracy: 0.6507999300956726\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss: 0.6868867874145508 Validation Accuracy: 0.6501998901367188\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss: 0.6202932596206665 Validation Accuracy: 0.655799925327301\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 0.719651997089386 Validation Accuracy: 0.6515998840332031\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss: 0.717207133769989 Validation Accuracy: 0.6517999172210693\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss: 0.6782808303833008 Validation Accuracy: 0.6563999056816101\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss: 0.6728718876838684 Validation Accuracy: 0.6577998995780945\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss: 0.6580290198326111 Validation Accuracy: 0.6507998704910278\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 0.7293089628219604 Validation Accuracy: 0.6499999165534973\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss: 0.7285014986991882 Validation Accuracy: 0.650999903678894\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss: 0.6592695713043213 Validation Accuracy: 0.6631998419761658\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss: 0.652294397354126 Validation Accuracy: 0.6583998799324036\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss: 0.6593511700630188 Validation Accuracy: 0.6523998975753784\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 0.7282378673553467 Validation Accuracy: 0.6601998805999756\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss: 0.6885420083999634 Validation Accuracy: 0.6577998995780945\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss: 0.6448256969451904 Validation Accuracy: 0.6649998426437378\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss: 0.6560694575309753 Validation Accuracy: 0.6581998467445374\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss: 0.6343237161636353 Validation Accuracy: 0.6573998928070068\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 0.6887800693511963 Validation Accuracy: 0.6609998941421509\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss: 0.682455837726593 Validation Accuracy: 0.6595999002456665\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss: 0.6540341973304749 Validation Accuracy: 0.6539998650550842\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss: 0.6161919236183167 Validation Accuracy: 0.6623998284339905\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss: 0.6278207898139954 Validation Accuracy: 0.6609998941421509\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 0.7299423813819885 Validation Accuracy: 0.6595998406410217\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss: 0.6808252930641174 Validation Accuracy: 0.6583998799324036\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss: 0.6507503390312195 Validation Accuracy: 0.6589998602867126\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss: 0.6251783967018127 Validation Accuracy: 0.6589999198913574\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss: 0.6130631566047668 Validation Accuracy: 0.6517998576164246\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 0.679780900478363 Validation Accuracy: 0.6649998426437378\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss: 0.6622314453125 Validation Accuracy: 0.6561999320983887\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss: 0.6203604936599731 Validation Accuracy: 0.6595999002456665\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss: 0.6279855370521545 Validation Accuracy: 0.6561998724937439\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss: 0.6162816882133484 Validation Accuracy: 0.6575998663902283\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 0.6892375946044922 Validation Accuracy: 0.6639998555183411\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss: 0.6611122488975525 Validation Accuracy: 0.6579998731613159\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss: 0.5997264385223389 Validation Accuracy: 0.6583999395370483\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss: 0.5908254384994507 Validation Accuracy: 0.6631999015808105\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss: 0.5852259397506714 Validation Accuracy: 0.6605998873710632\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 0.673857569694519 Validation Accuracy: 0.6583998799324036\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss: 0.6596553921699524 Validation Accuracy: 0.6553999185562134\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss: 0.5944095849990845 Validation Accuracy: 0.6595998406410217\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss: 0.6081539392471313 Validation Accuracy: 0.6571999192237854\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss: 0.5845593214035034 Validation Accuracy: 0.6569998860359192\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 0.6444097757339478 Validation Accuracy: 0.6535998582839966\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss: 0.6417034864425659 Validation Accuracy: 0.6607998609542847\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss: 0.6153334379196167 Validation Accuracy: 0.6619998812675476\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss: 0.6241508722305298 Validation Accuracy: 0.6553999185562134\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss: 0.5762432813644409 Validation Accuracy: 0.6545999050140381\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 0.6415567398071289 Validation Accuracy: 0.6623998880386353\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss: 0.6243907809257507 Validation Accuracy: 0.6637999415397644\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss: 0.5999513268470764 Validation Accuracy: 0.6571998596191406\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss: 0.6184510588645935 Validation Accuracy: 0.6553998589515686\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss: 0.5686973929405212 Validation Accuracy: 0.6569998860359192\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 0.6523320078849792 Validation Accuracy: 0.6619998812675476\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss: 0.6242916584014893 Validation Accuracy: 0.666999876499176\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss: 0.5841525793075562 Validation Accuracy: 0.662199854850769\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss: 0.5862792134284973 Validation Accuracy: 0.6521998643875122\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss: 0.5559588074684143 Validation Accuracy: 0.6575998663902283\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 0.6295190453529358 Validation Accuracy: 0.6631999015808105\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss: 0.6307855248451233 Validation Accuracy: 0.6559998989105225\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss: 0.5851352214813232 Validation Accuracy: 0.6643999218940735\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss: 0.5763124227523804 Validation Accuracy: 0.6547998785972595\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss: 0.5905020236968994 Validation Accuracy: 0.6477999091148376\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 0.6541765928268433 Validation Accuracy: 0.6611998677253723\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss: 0.6138322949409485 Validation Accuracy: 0.662199854850769\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss: 0.5493804812431335 Validation Accuracy: 0.6617999076843262\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss: 0.5896658301353455 Validation Accuracy: 0.655799925327301\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss: 0.5756773948669434 Validation Accuracy: 0.6541998386383057\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 0.6540684103965759 Validation Accuracy: 0.662199854850769\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss: 0.6099083423614502 Validation Accuracy: 0.6561999320983887\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss: 0.5745465755462646 Validation Accuracy: 0.6583998799324036\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss: 0.5650849342346191 Validation Accuracy: 0.6637998819351196\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss: 0.5510091781616211 Validation Accuracy: 0.6549999713897705\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 0.6107701063156128 Validation Accuracy: 0.6597998738288879\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss: 0.6119526028633118 Validation Accuracy: 0.6603999137878418\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss: 0.5649961233139038 Validation Accuracy: 0.6567999124526978\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss: 0.5787850022315979 Validation Accuracy: 0.6515998840332031\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss: 0.5594234466552734 Validation Accuracy: 0.6507998704910278\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 0.6182122230529785 Validation Accuracy: 0.663399875164032\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss: 0.6029595136642456 Validation Accuracy: 0.6653999090194702\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss: 0.5556149482727051 Validation Accuracy: 0.6629999279975891\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss: 0.5588113069534302 Validation Accuracy: 0.6591998934745789\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss: 0.512192964553833 Validation Accuracy: 0.6575998663902283\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 0.6000471711158752 Validation Accuracy: 0.6611998677253723\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss: 0.6000359654426575 Validation Accuracy: 0.6613999009132385\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss: 0.5196250677108765 Validation Accuracy: 0.6635999083518982\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss: 0.5577845573425293 Validation Accuracy: 0.6577998995780945\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss: 0.5432686805725098 Validation Accuracy: 0.6569998860359192\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 0.5897151231765747 Validation Accuracy: 0.6623998880386353\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss: 0.5938180088996887 Validation Accuracy: 0.6583998203277588\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss: 0.5456828474998474 Validation Accuracy: 0.6551998853683472\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss: 0.581397294998169 Validation Accuracy: 0.6569998860359192\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss: 0.5489562749862671 Validation Accuracy: 0.6495998501777649\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 0.5689614415168762 Validation Accuracy: 0.6609998941421509\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss: 0.57197105884552 Validation Accuracy: 0.6597998738288879\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss: 0.5621220469474792 Validation Accuracy: 0.6573998928070068\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss: 0.5549784302711487 Validation Accuracy: 0.6577998995780945\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss: 0.5434823036193848 Validation Accuracy: 0.652199923992157\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 0.5848038196563721 Validation Accuracy: 0.6617999076843262\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss: 0.5721086859703064 Validation Accuracy: 0.6609998941421509\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss: 0.5394384860992432 Validation Accuracy: 0.6611998677253723\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss: 0.5362913012504578 Validation Accuracy: 0.6601998805999756\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss: 0.5049556493759155 Validation Accuracy: 0.662199854850769\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 0.6029381155967712 Validation Accuracy: 0.658599853515625\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss: 0.5497778654098511 Validation Accuracy: 0.6593999266624451\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss: 0.5274587869644165 Validation Accuracy: 0.6607999205589294\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss: 0.5333272814750671 Validation Accuracy: 0.6563998460769653\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss: 0.5267530679702759 Validation Accuracy: 0.6519998908042908\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 0.6179713010787964 Validation Accuracy: 0.6571998596191406\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss: 0.5551601648330688 Validation Accuracy: 0.6611998677253723\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss: 0.5168132185935974 Validation Accuracy: 0.6581999063491821\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss: 0.5317621827125549 Validation Accuracy: 0.6593998670578003\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss: 0.5123860239982605 Validation Accuracy: 0.650999903678894\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 0.5684594511985779 Validation Accuracy: 0.6643998622894287\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss: 0.5841788649559021 Validation Accuracy: 0.6541998386383057\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss: 0.5074419379234314 Validation Accuracy: 0.6599998474121094\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss: 0.5264043211936951 Validation Accuracy: 0.6565998792648315\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss: 0.4955955147743225 Validation Accuracy: 0.66159987449646\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 0.5853551626205444 Validation Accuracy: 0.6535998582839966\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss: 0.5743515491485596 Validation Accuracy: 0.6613999009132385\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss: 0.5153607726097107 Validation Accuracy: 0.6569998860359192\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss: 0.550381064414978 Validation Accuracy: 0.6519998908042908\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss: 0.5211287140846252 Validation Accuracy: 0.6559998989105225\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 0.5827869176864624 Validation Accuracy: 0.6533998847007751\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss: 0.5921745300292969 Validation Accuracy: 0.6579998731613159\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss: 0.5309321880340576 Validation Accuracy: 0.6573998928070068\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss: 0.5124940872192383 Validation Accuracy: 0.6543998718261719\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss: 0.4993882477283478 Validation Accuracy: 0.657599925994873\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 0.5667426586151123 Validation Accuracy: 0.6649998426437378\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss: 0.5497773885726929 Validation Accuracy: 0.6565998792648315\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss: 0.4846700131893158 Validation Accuracy: 0.6639999151229858\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss: 0.4965808391571045 Validation Accuracy: 0.6567999124526978\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss: 0.4644138216972351 Validation Accuracy: 0.6597998738288879\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 0.5491877198219299 Validation Accuracy: 0.6645998954772949\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss: 0.5617112517356873 Validation Accuracy: 0.6603999137878418\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss: 0.5126520395278931 Validation Accuracy: 0.6563998460769653\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss: 0.5032552480697632 Validation Accuracy: 0.6635999083518982\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss: 0.4948352575302124 Validation Accuracy: 0.6627998352050781\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 0.5479719638824463 Validation Accuracy: 0.6571998596191406\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss: 0.5238873958587646 Validation Accuracy: 0.6597998738288879\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss: 0.49816712737083435 Validation Accuracy: 0.6677998304367065\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss: 0.49732521176338196 Validation Accuracy: 0.6611998677253723\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss: 0.4886208772659302 Validation Accuracy: 0.6623998880386353\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 0.5470154881477356 Validation Accuracy: 0.6599999070167542\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss: 0.5223602652549744 Validation Accuracy: 0.6617999076843262\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss: 0.4808379113674164 Validation Accuracy: 0.6649998426437378\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss: 0.4794755280017853 Validation Accuracy: 0.666999876499176\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss: 0.5122271776199341 Validation Accuracy: 0.6629998683929443\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 0.5337387323379517 Validation Accuracy: 0.6627998948097229\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss: 0.5338001251220703 Validation Accuracy: 0.6577998399734497\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss: 0.4723219871520996 Validation Accuracy: 0.6579999327659607\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss: 0.4944913983345032 Validation Accuracy: 0.653799831867218\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss: 0.4721361994743347 Validation Accuracy: 0.6563998460769653\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss: 0.5300983786582947 Validation Accuracy: 0.660399854183197\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss: 0.5052968859672546 Validation Accuracy: 0.6639998555183411\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss: 0.47054678201675415 Validation Accuracy: 0.6625998616218567\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss: 0.48698878288269043 Validation Accuracy: 0.6593999266624451\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss: 0.47356951236724854 Validation Accuracy: 0.6601998805999756\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss: 0.5150800943374634 Validation Accuracy: 0.6619998812675476\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss: 0.5050771832466125 Validation Accuracy: 0.6643998622894287\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss: 0.471017986536026 Validation Accuracy: 0.662199854850769\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss: 0.49569404125213623 Validation Accuracy: 0.6583999395370483\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss: 0.47925129532814026 Validation Accuracy: 0.6565998792648315\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss: 0.5438456535339355 Validation Accuracy: 0.6601998805999756\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss: 0.5190486907958984 Validation Accuracy: 0.66159987449646\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss: 0.48939085006713867 Validation Accuracy: 0.6583999395370483\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss: 0.4816598892211914 Validation Accuracy: 0.6617998480796814\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss: 0.4772834777832031 Validation Accuracy: 0.6523998379707336\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss: 0.5043061971664429 Validation Accuracy: 0.6597998738288879\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss: 0.5030533075332642 Validation Accuracy: 0.6581999659538269\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss: 0.4524599015712738 Validation Accuracy: 0.6613998413085938\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss: 0.4681180417537689 Validation Accuracy: 0.6575998663902283\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss: 0.4390874207019806 Validation Accuracy: 0.6517999172210693\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss: 0.5024390816688538 Validation Accuracy: 0.6599998474121094\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss: 0.5106208324432373 Validation Accuracy: 0.6581999063491821\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss: 0.4638536274433136 Validation Accuracy: 0.6607998609542847\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss: 0.46831780672073364 Validation Accuracy: 0.6579999327659607\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss: 0.4202737510204315 Validation Accuracy: 0.6611998677253723\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss: 0.4895677864551544 Validation Accuracy: 0.660399854183197\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss: 0.5009196996688843 Validation Accuracy: 0.6583998799324036\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss: 0.477727472782135 Validation Accuracy: 0.6585999131202698\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss: 0.4811885952949524 Validation Accuracy: 0.6493999361991882\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss: 0.4324261546134949 Validation Accuracy: 0.6569998860359192\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss: 0.5041936635971069 Validation Accuracy: 0.6563999056816101\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss: 0.4683454632759094 Validation Accuracy: 0.6611998677253723\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss: 0.45666569471359253 Validation Accuracy: 0.6649999022483826\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss: 0.45024019479751587 Validation Accuracy: 0.6609998345375061\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss: 0.4311593770980835 Validation Accuracy: 0.6519999504089355\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss: 0.515270471572876 Validation Accuracy: 0.6569998264312744\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss: 0.4769471287727356 Validation Accuracy: 0.6609998941421509\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss: 0.48248305916786194 Validation Accuracy: 0.6619998812675476\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss: 0.4629528224468231 Validation Accuracy: 0.6543998718261719\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss: 0.43283218145370483 Validation Accuracy: 0.656799852848053\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss: 0.503298819065094 Validation Accuracy: 0.6583998203277588\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss: 0.4838734269142151 Validation Accuracy: 0.662199854850769\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss: 0.45094555616378784 Validation Accuracy: 0.6653998494148254\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss: 0.4575919210910797 Validation Accuracy: 0.6607998609542847\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss: 0.42375442385673523 Validation Accuracy: 0.6627998352050781\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss: 0.4843207895755768 Validation Accuracy: 0.6629998683929443\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss: 0.4775722026824951 Validation Accuracy: 0.6605998277664185\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss: 0.44836288690567017 Validation Accuracy: 0.6597998738288879\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss: 0.4360107183456421 Validation Accuracy: 0.662199854850769\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss: 0.4137094020843506 Validation Accuracy: 0.6597998738288879\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss: 0.4839564263820648 Validation Accuracy: 0.6673998832702637\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss: 0.4750784635543823 Validation Accuracy: 0.6671999096870422\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss: 0.45166149735450745 Validation Accuracy: 0.6563999056816101\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss: 0.4255984127521515 Validation Accuracy: 0.6575998663902283\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss: 0.41588205099105835 Validation Accuracy: 0.6589998602867126\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss: 0.49746453762054443 Validation Accuracy: 0.6551998853683472\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss: 0.47872215509414673 Validation Accuracy: 0.6551999449729919\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss: 0.4545131027698517 Validation Accuracy: 0.6589999198913574\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss: 0.42541277408599854 Validation Accuracy: 0.6573998928070068\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss: 0.42351335287094116 Validation Accuracy: 0.654999852180481\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss: 0.492563933134079 Validation Accuracy: 0.6651999354362488\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss: 0.47102242708206177 Validation Accuracy: 0.6611998677253723\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss: 0.4399406611919403 Validation Accuracy: 0.6563998460769653\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss: 0.44487708806991577 Validation Accuracy: 0.6469998359680176\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss: 0.39997780323028564 Validation Accuracy: 0.6543999314308167\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss: 0.4632439911365509 Validation Accuracy: 0.6645998358726501\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss: 0.4879648983478546 Validation Accuracy: 0.6593998670578003\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss: 0.43463370203971863 Validation Accuracy: 0.662199854850769\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss: 0.43467020988464355 Validation Accuracy: 0.6555998921394348\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss: 0.4097070097923279 Validation Accuracy: 0.6595999002456665\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss: 0.46659940481185913 Validation Accuracy: 0.6617999076843262\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss: 0.48959511518478394 Validation Accuracy: 0.644399881362915\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss: 0.43815168738365173 Validation Accuracy: 0.6555998921394348\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss: 0.43540000915527344 Validation Accuracy: 0.6521998643875122\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss: 0.39665746688842773 Validation Accuracy: 0.6567999124526978\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss: 0.47275763750076294 Validation Accuracy: 0.6613998413085938\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss: 0.44218260049819946 Validation Accuracy: 0.6601998805999756\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss: 0.4297932982444763 Validation Accuracy: 0.6583999395370483\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss: 0.4270094335079193 Validation Accuracy: 0.6483998894691467\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss: 0.4038424789905548 Validation Accuracy: 0.6479998826980591\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss: 0.46950197219848633 Validation Accuracy: 0.6519998908042908\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss: 0.44251254200935364 Validation Accuracy: 0.655799925327301\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss: 0.4358065724372864 Validation Accuracy: 0.6635999083518982\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss: 0.42518526315689087 Validation Accuracy: 0.6479998230934143\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss: 0.382802277803421 Validation Accuracy: 0.658599853515625\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss: 0.46883755922317505 Validation Accuracy: 0.6565998792648315\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss: 0.4654484689235687 Validation Accuracy: 0.6543998718261719\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss: 0.4205564856529236 Validation Accuracy: 0.6583998799324036\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss: 0.41053301095962524 Validation Accuracy: 0.6567999124526978\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss: 0.4074879288673401 Validation Accuracy: 0.6513999104499817\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss: 0.48355555534362793 Validation Accuracy: 0.655799925327301\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss: 0.4481569230556488 Validation Accuracy: 0.653999924659729\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss: 0.42111653089523315 Validation Accuracy: 0.6601998805999756\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss: 0.4090740382671356 Validation Accuracy: 0.6601998805999756\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss: 0.415054053068161 Validation Accuracy: 0.6461999416351318\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss: 0.4739367961883545 Validation Accuracy: 0.660399854183197\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss: 0.46185460686683655 Validation Accuracy: 0.6555998921394348\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss: 0.4108288884162903 Validation Accuracy: 0.6589998602867126\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss: 0.41921308636665344 Validation Accuracy: 0.6471999287605286\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss: 0.39572760462760925 Validation Accuracy: 0.6485998630523682\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss: 0.44942283630371094 Validation Accuracy: 0.6583998799324036\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss: 0.4620975852012634 Validation Accuracy: 0.6567999124526978\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss: 0.4201051890850067 Validation Accuracy: 0.6617999076843262\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss: 0.41153138875961304 Validation Accuracy: 0.6491998434066772\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss: 0.3877025842666626 Validation Accuracy: 0.6513999104499817\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss: 0.4507920444011688 Validation Accuracy: 0.6589998602867126\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss: 0.4694308936595917 Validation Accuracy: 0.653799831867218\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss: 0.4229520261287689 Validation Accuracy: 0.6597999334335327\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss: 0.39374542236328125 Validation Accuracy: 0.649199903011322\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss: 0.3826751708984375 Validation Accuracy: 0.6485999226570129\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss: 0.44284799695014954 Validation Accuracy: 0.6497998237609863\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss: 0.44730326533317566 Validation Accuracy: 0.6503998637199402\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss: 0.40708696842193604 Validation Accuracy: 0.6535999178886414\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss: 0.3843756318092346 Validation Accuracy: 0.6521998643875122\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss: 0.3718642592430115 Validation Accuracy: 0.6475998759269714\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss: 0.4577648639678955 Validation Accuracy: 0.6547999382019043\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss: 0.4423670172691345 Validation Accuracy: 0.6545998454093933\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss: 0.42854589223861694 Validation Accuracy: 0.663399875164032\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss: 0.4198516011238098 Validation Accuracy: 0.6499998569488525\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss: 0.3821415901184082 Validation Accuracy: 0.649199903011322\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss: 0.4829617440700531 Validation Accuracy: 0.6415998935699463\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss: 0.47086673974990845 Validation Accuracy: 0.6471999287605286\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss: 0.4054490029811859 Validation Accuracy: 0.6581999063491821\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss: 0.39265623688697815 Validation Accuracy: 0.6517998576164246\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss: 0.42619773745536804 Validation Accuracy: 0.637799859046936\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss: 0.453874796628952 Validation Accuracy: 0.6487998962402344\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss: 0.41757309436798096 Validation Accuracy: 0.6519998908042908\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss: 0.39770567417144775 Validation Accuracy: 0.6619998812675476\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss: 0.3977155387401581 Validation Accuracy: 0.6497998833656311\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss: 0.38080310821533203 Validation Accuracy: 0.6419999003410339\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss: 0.4761202037334442 Validation Accuracy: 0.6387999057769775\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss: 0.41682168841362 Validation Accuracy: 0.6521998643875122\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss: 0.41227278113365173 Validation Accuracy: 0.6623998880386353\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss: 0.40634647011756897 Validation Accuracy: 0.6525999307632446\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss: 0.3864680528640747 Validation Accuracy: 0.6427999138832092\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss: 0.46578118205070496 Validation Accuracy: 0.6459998488426208\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss: 0.4208841919898987 Validation Accuracy: 0.6559998989105225\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss: 0.3821554183959961 Validation Accuracy: 0.660599946975708\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss: 0.38592806458473206 Validation Accuracy: 0.6553999185562134\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss: 0.3613070845603943 Validation Accuracy: 0.6413998603820801\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss: 0.43301260471343994 Validation Accuracy: 0.6467999219894409\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss: 0.44630828499794006 Validation Accuracy: 0.650199830532074\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss: 0.3907604515552521 Validation Accuracy: 0.6571998596191406\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss: 0.3572554588317871 Validation Accuracy: 0.6605998873710632\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss: 0.37897783517837524 Validation Accuracy: 0.6469998955726624\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss: 0.4454304277896881 Validation Accuracy: 0.6429999470710754\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss: 0.40006133913993835 Validation Accuracy: 0.6577998995780945\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss: 0.3956628441810608 Validation Accuracy: 0.660399854183197\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss: 0.3965890109539032 Validation Accuracy: 0.6521998643875122\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss: 0.3748991787433624 Validation Accuracy: 0.6425999402999878\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.6408030807971954\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8cf686c710>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
